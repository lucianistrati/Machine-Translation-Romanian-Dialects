% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[review]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Machine Translation Romanian Dialects \\
		\hfill \\
		\hfill \\
		\small{1st Semester of 2022-2023}}

  \author{Claudiu Creanga \\
  \texttt{ccreanga@s.unibuc.ro} \\\And
  Lucian Istrati \\
  \texttt{listrati@s.unibuc.ro} \\}

\begin{document}
\maketitle
\begin{abstract}
\textbf This is a collection of tools that are helpful in doing translation work between Romanian sub-dialects.
It also has several analyses that show the differences between sub-dialects, or as they are called in Romanian: graiuri.
\end{abstract}


\section*{Use the project}
\begin{enumerate}
	\item Download the code from this public repository https://github.com/lucianistrati/Machine-Translation-Romanian-Dialects
	\item You can also download models from huggingface: https://huggingface.co/fmi-unibuc
	\item To use the "oltenizator" program which changes the tense from passe compose to passe simple, use this command inside {src/oltenizator} subfolder: python {tense\_changer.py -s "A aranjat camera."}
	\item To change it from passe simple to passe compose add the -r flag: {python tense\_changer.py -s "Aranjai camera." -r }
	\item SpacY doesn't detect very well the passe simple tense, so the reverse swapping doesn't work as well as the first one.
	\item {Analysis.py} can be used to show the most common used words by every Romanian sub-dialect. It shows also plots with the data.
	\item {Train\_word2vec.py} is used to train a word2vec CBOW model over all the books in every dialect;
	\item {compare\_anns.py	} is used to compare how accurate were the Speech-To-Text transcriptions between Sonix-Ai and Vatis-Tech solutions. This is a place where new contributions can be made as the current analysis lacks in depth.
 	\item mat.py is used to obtain a similarity matrix between the overlaps of each dialect;
  	\item Translation.py has all the translation functionality needed to translate from one dialect to another;
   	\item {detect\_dialect.py} is used to detect the dialect from a text.
        \item Utils.py has several dictionaries that contains useful rules for translation as well as mapping of the videos and the books to dialect labels.
        \item {Train\_model.py} is used to trains a model to be able to classify in what dialect a text is in.
\end{enumerate}

\begin{enumerate}
    \item \textbf{Data Acquisition}
        \subitem Scrap the wikidictionary website for a list of Romanian verbs.
        \subitem Scrap the conjugari.ro website for the rules by which a verb can be conjugated: regular or irregular verbs.
        \subitem Manually clean these datasets.
        \subitem Collect books and texts from each dialect. We created a first dataset of sub-dialects books: RoBoDi.
        \subitem Collect audio from speakers of Romanian sub-dialects and start making a first dataset in this field: RAuDI (posted on huggingface).
        \subitem Scrap dexonline for words and their dialect (work in progress).
    \item \textbf{Evaluation}
        \subitem Evaluate the systems manually.
        \subitem Spot where it makes mistakes and refactor code.
        \subitem Due to a lack of data we found it hard to evaluate it automatically.
\end{enumerate}


\newpage

\section{Introduction}
\label{section:intro}

Because there are very few analyses at sub-dialect level in Romanian we thought about this project as a collection of tools to provide and enable analyses in this domain.

We are trying to solve 3 problems:
\begin{itemize}
	\item to make a program that can detect a Romanian sub-dialect from a random Romanian text.
	\item to make a program that can evaluate how well current speech to text tools work with Romanian sub-dialects.
	\item to make a program that changes a text from a dialect to another.
	\item because of lack of data we created a dataset of regionalisms and arhaisms (RoAcReL): 1942 rows and 47 columns: ['Word', 'Meaning', 'First mention', 'IsInDexOrNot', 'County/Region', 'IsItUsedNow', 'Source']. The data was collected from the following regions: 'Dobrogea', 'Muntenia', 'Moldova/Transilvania', 'Transilvania', 'Ardeal', 'Maramureș', 'Bucovina / Republica Moldova', 'Bucovina', 'Moldova', 'Comuna Suharău, Județul Botoșani', 'Comuna Șerbănești, Județul Olt', 'Oltenia', 'Sudul Moldovei', 'Banat';
	\item we didn't find analyses done on these problems before.
\end{itemize}

The tense changer gives very good results:
\begin{center}
\begin{tabular}{ |c|c| }
 \hline
 Tu ai plecat in parcare. & Tu plecași in parcare. \\
 Noi am fost la plimbare. & Noi furăm la plimbare.  \\
 Ei au negat minciuna. & Ei negară minciuna.  \\
 Au negat minciuna. & negară minciuna.  \\
 Eu am argumentat bine. & Eu argumentai bine.  \\
 \hline
\end{tabular}
\end{center}

We labelled a text or book with a certain dialect and got the following results:
\begin{itemize}
	\item 101 Basme Romanesti {'ardelean': 0.30, 'banatean': 0.25, 'maramuresean': 0.32, 'moldovean': 0.06, 'oltean': 0.17}
	\item Radu Rosetti, Parintele Zosim {'ardelean': 0.28, 'banatean': 0.24, 'maramuresean': 0.30, 'moldovean': 0.05, 'oltean': 0.12}
 	\item Povesti populare romanesti {'ardelean': 0.37, 'banatean': 0.31, 'maramuresean': 0.27, 'moldovean': 0.02, 'oltean': 0.08}
 	\item Comorile poporului Radulescu Constantin Bucuresti 1930 {'ardelean': 0.31, 'banatean': 0.25, 'maramuresean': 0.25, 'moldovean': 0.02, 'oltean': 0.07}
\end{itemize}

We analized the similarity of the vocabulary of each sub-dialect and found that, as expected, that we can split them in Nordic and Sudic groups:
\graphicspath{ {./images/} }
\includegraphics[scale=0.5]{dialect}



\section{Approach}
\label{section:approach}

The code is public and can be used from here: https://github.com/lucianistrati/Machine-Translation-Romanian-Dialects
The models are here:  https://huggingface.co/fmi-unibuc
Tools that we used:
\begin{enumerate}
 	\item SpacY and nltk for different NLP tasks like POS and Morphology tagging.
	\item Dexonline, youtube, conjugari.ro for data gathering.
	\item project was done in python.
\end{enumerate}

The training was done in Google collab.

\section{Limitations}
\label{section:limitations}
The biggest limitation we have is that we didn't manage to use the full capabilities of dexonline. If we used more data from there we could have improved our model more.

Regarding our Speech-to-Text task, there were only a few tools available in Romanian: Google, Sonix-ai and Vatis-tech. All 3 tools required a paid subscription after the first couple of minutes of free use.

\section{Conclusions and Future Work}
\label{section:conclusions}
We liked the project because it provided us the opportunity to do novel research for Romanian language.

Like we said before, the best place to do future contributions in this project would be to use more data from dexonline and improve the model.



\end{document}